pretrain:
resume: "/home/heyuxin/anaconda3/envs/pytorch/SDA-CLIP-main/exp/clip_surgvisdom/ViT-B/16/SurgVisDom/20250303-1236/last_model.pt"
seed: 1024
data:
    dataset: SurgVisDom
    modality: RGB
    num_segments: 16
    seg_length: 1
    split: 1
    batch_size: 16
    workers: 16
    gpus: 2
    num_classes: 3
    image_tmpl: ['img_{:05d}.jpeg', 'img_{:05d}.png', 'img_{:05d}.jpg']
    train_list: '/home/heyuxin/anaconda3/envs/pytorch/SDA-CLIP-main/lists/surgvisdom/train_frames.txt' #
    val_list: '/home/heyuxin/anaconda3/envs/pytorch/SDA-CLIP-main/lists/surgvisdom/val_frames.txt' #
    label_list: 'lists/SurgVisDom_labels.csv'
    index_bias: 0
    input_size: 224
    randaug:
        N: 4  #2
        M: 9  #9
network:
    arch: ViT-B/16  #ViT-B/32 ViT-B/16
    init: True 
    drop_out: 0.0 
    emb_dropout: 0.0 
    type: clip_surgvisdom
    sim_header: "Transf"  #Transf   meanP   LSTM   Transf_cls Conv_1D
    fix_text: False
    fix_img: False
    describe:
solver:
    ii_tt: 0.2
    type: cosine
    epochs: 30
    start_epoch: 0
    epoch_offset: 0
    optim: adamw
    lr: 3.e-5
    lr_warmup_step: 5
    momentum: 0.9
    weight_decay: 0.2
    lr_decay_step: 15
    lr_decay_factor: 0.1
    clip_gradient: 20
    loss_type: nll
    evaluate: False
    ratio: 1
    f_ratio: 10
logging:
    print_freq: 10
    eval_freq: 10